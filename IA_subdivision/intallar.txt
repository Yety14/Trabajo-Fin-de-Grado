# Instalar Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Descargar modelo
ollama pull llama2

# Arrancar servidor (en otra terminal)
ollama serve


Ejecutar Ollama
python3 master_ollama.py

Consultar decisi√≥n con IA
curl http://localhost:5000/get_best_node_ollama?system_load=high
